{"cells":[{"cell_type":"markdown","metadata":{},"source":["\n","# **Librairies**"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T23:32:37.602603Z","iopub.status.busy":"2024-06-05T23:32:37.602220Z","iopub.status.idle":"2024-06-05T23:34:05.552282Z","shell.execute_reply":"2024-06-05T23:34:05.551305Z","shell.execute_reply.started":"2024-06-05T23:32:37.602569Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting bitsandbytes\n","  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.43.1\n","Collecting peft\n","  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\n","Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.39.3)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\n","Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.29.3)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.22.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: peft\n","Successfully installed peft-0.11.1\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"]},{"name":"stderr","output_type":"stream","text":["2024-06-05 23:33:51.306875: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-05 23:33:51.307012: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-05 23:33:51.589789: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["# Installer les bibliothèques nécessaires\n","!pip install bitsandbytes\n","!pip install peft\n","!pip install datasets\n","!pip install accelerate\n","\n","# Importer les bibliothèques requises pour le traitement, l'entraînement et l'accélération\n","import accelerate\n","import torch\n","import torch.nn as nn\n","import bitsandbytes as bnb\n","from transformers import DistilBertTokenizer, DistilBertModel, Trainer, TrainingArguments, AutoModelForSequenceClassification, DataCollatorWithPadding\n","from peft import LoraConfig, get_peft_model, PeftModel\n","from datasets import load_dataset\n","import re\n","\n","# Définir une fonction pour obtenir le dispositif (GPU si disponible, sinon CPU)\n","def get_device_map() -> str:\n","    return 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Définir le dispositif à utiliser pour l'entraînement et l'inférence\n","device = get_device_map() "]},{"cell_type":"markdown","metadata":{},"source":["# **Loading the Base Model to Fine-tune**"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T23:34:54.022266Z","iopub.status.busy":"2024-06-05T23:34:54.021601Z","iopub.status.idle":"2024-06-05T23:34:59.387414Z","shell.execute_reply":"2024-06-05T23:34:59.386166Z","shell.execute_reply.started":"2024-06-05T23:34:54.022236Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0081050c11f84940b2bfae79e7a8a09c","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e957097aa7ad4f3683c80eb03db72641","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ad3bcf442594c59a4e3c7e137ce8d02","version_major":2,"version_minor":0},"text/plain":["spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45fee0db9c8a441492f84aebde232e52","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n","Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","# Charger le modèle pré-entraîné\n","### Si vous voulez travailler avec LLaMa2, décommentez les lignes suivantes\n","\"\"\"model = AutoModelForCausalLM.from_pretrained(\n","    \"meta-llama/Llama-2-7b-chat-hf\",\n","    cache_dir=\"/data/yash/base_models\",\n","    device_map='auto'\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",\n","                                          cache_dir=\"/data/yash/base_models\"\n","                                         )\"\"\"\n","\n","## Pour travailler avec DeBERTa, On utilise le code ci-dessous\n","model_name = \"microsoft/deberta-v3-base\"  \n","# Charger le tokenizer DeBERTa\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","# Charger le modèle DeBERTa pour la classification de séquences\n","model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)  "]},{"cell_type":"markdown","metadata":{},"source":["# **Processing des Données**"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T23:35:19.429025Z","iopub.status.busy":"2024-06-05T23:35:19.428262Z","iopub.status.idle":"2024-06-05T23:35:26.830881Z","shell.execute_reply":"2024-06-05T23:35:26.829938Z","shell.execute_reply.started":"2024-06-05T23:35:19.428992Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebaf1ef251674a5da7703c670b42cf0d","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/487 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Downloading data: 100%|██████████| 78.4M/78.4M [00:01<00:00, 58.3MB/s]\n","Downloading data: 100%|██████████| 15.5M/15.5M [00:00<00:00, 30.0MB/s]\n","Downloading data: 100%|██████████| 22.0M/22.0M [00:00<00:00, 29.6MB/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53cdff6e5ea844f385285ed35cf373b7","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc65c65042a04c30ae1a9cd67f72f0c0","version_major":2,"version_minor":0},"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12d785ebd7da4f86b77f74370bf00cf4","version_major":2,"version_minor":0},"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Charger le jeu de données à partir du hub Hugging Face\n","data = load_dataset(\"ErfanMoosaviMonazzah/fake-news-detection-dataset-English\", cache_dir = \"/data/datasets\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T23:35:30.532463Z","iopub.status.busy":"2024-06-05T23:35:30.532024Z","iopub.status.idle":"2024-06-05T23:35:30.540494Z","shell.execute_reply":"2024-06-05T23:35:30.539366Z","shell.execute_reply.started":"2024-06-05T23:35:30.532426Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['Unnamed: 0', 'title', 'text', 'subject', 'date', 'label'],\n","        num_rows: 30000\n","    })\n","    validation: Dataset({\n","        features: ['Unnamed: 0', 'title', 'text', 'subject', 'date', 'label'],\n","        num_rows: 6000\n","    })\n","    test: Dataset({\n","        features: ['Unnamed: 0', 'title', 'text', 'subject', 'date', 'label'],\n","        num_rows: 8267\n","    })\n","})"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T23:35:37.660883Z","iopub.status.busy":"2024-06-05T23:35:37.660528Z","iopub.status.idle":"2024-06-05T23:35:37.666508Z","shell.execute_reply":"2024-06-05T23:35:37.665447Z","shell.execute_reply.started":"2024-06-05T23:35:37.660856Z"},"trusted":true},"outputs":[],"source":["def process_data(example):\n","# Combinons le titre, le sujet et le texte pour créer un prompt unique.\n","  example ['prompt']=\"the news title is: \" + example['title']+\"\\n\\n\"+\"The subject of the news is: \" +  example['subject']+\"\\n\\n\" + \"The body text of the news is: \" + example['text'] + '\\n\\n'\n","# Ajoutons une étiquette indiquant si la nouvelle est vraie ou fausse.\n","  example['complete_prompt'] = example['prompt']+ \"this news is \" + (\"fake\" if example['label']==0 else \"real\")\n","  return example"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T23:35:48.884995Z","iopub.status.busy":"2024-06-05T23:35:48.884664Z","iopub.status.idle":"2024-06-05T23:35:57.101956Z","shell.execute_reply":"2024-06-05T23:35:57.100942Z","shell.execute_reply.started":"2024-06-05T23:35:48.884959Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e65590673b794739a800d96b1d948217","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27e5687306b84a19a525e761a2f5d476","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c120b0a369534fd5950ca331aac18d52","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/8267 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Appliquons la fonction de traitement \n","data = data.map(process_data)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T23:35:59.435797Z","iopub.status.busy":"2024-06-05T23:35:59.434841Z","iopub.status.idle":"2024-06-05T23:35:59.441460Z","shell.execute_reply":"2024-06-05T23:35:59.440387Z","shell.execute_reply.started":"2024-06-05T23:35:59.435763Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['Unnamed: 0', 'title', 'text', 'subject', 'date', 'label', 'prompt', 'complete_prompt'],\n","        num_rows: 30000\n","    })\n","    validation: Dataset({\n","        features: ['Unnamed: 0', 'title', 'text', 'subject', 'date', 'label', 'prompt', 'complete_prompt'],\n","        num_rows: 6000\n","    })\n","    test: Dataset({\n","        features: ['Unnamed: 0', 'title', 'text', 'subject', 'date', 'label', 'prompt', 'complete_prompt'],\n","        num_rows: 8267\n","    })\n","})"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T23:36:03.840463Z","iopub.status.busy":"2024-06-05T23:36:03.839590Z","iopub.status.idle":"2024-06-05T23:36:04.004601Z","shell.execute_reply":"2024-06-05T23:36:04.003637Z","shell.execute_reply.started":"2024-06-05T23:36:03.840431Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["the news title is: Federal Reserve governor Powell's policy views, in his own words\n","\n","The subject of the news is: politicsNews\n","\n","The body text of the news is: President Donald Trump on Thursday tapped Federal Reserve Governor Jerome Powell to become head of the U.S. central bank, promoting a soft-spoken centrist to replace Janet Yellen when her term expires in February 2018. In five years as a Fed Governor Jerome Powell has been a consistent, middle of the road voice, backing the consensus crafted by Fed chair Janet Yellen that interest rates should be raised slowly so labor markets could recover, that financial stability risks were muted, and that new regulations had made the economy safer. Following is a collection of quotes from select policy speeches he has delivered since 2015: On Rates:  “The financial crisis did significant damage to the productive capacity of our economy, and the damage was of a character, extent, and duration that cannot be fully known today…It seems plausible that at least part of this supply-side damage could be reversed if the economy enjoys a period of sustained growth.4 To encourage that outcome, as monetary policymakers consider removing accommodation, we should look for a little more proof than usual that labor markets are tightening or other supply-side constraints are binding.” - April 2015 speech to New York Council on Foreign Relations: (Graphic: U.S. labor market measures vs interest rates - reut.rs/2h7hsFx) On Financial Stability:  “The bottom line is that there has not been an excessive buildup of leverage, maturity transformation, or broadly unsustainable asset prices…Overall, I do not see leveraged finance markets as posing undue financial stability risks. And if risk-taking does not threaten financial stability, it is not the Fed’s job to stop people from losing (or making) money.”  - January 2017 speech to American Finance Association, Chicago  (Graphic: U.S. stocks and leverage - reut.rs/2iolCp6) On Regulation: “We have substantially increased the capital, liquidity, and other prudential requirements for large banking firms. These measures are not free. Higher capital requirements increase bank costs, and at least some of those costs will be passed along to bank customers and shareholders. But in the longer term, stronger prudential requirements for large banking firms will produce more sustainable credit availability and economic growth.” - June 2017 speech to Salzburg Global Seminar, Salzburg, Austria (Graphic: Commercial credit and bank profitability - reut.rs/2h8lfCm) On the Current Economy: “Risks to the forecast now seem more balanced than they have been for some time. In particular, the global picture has brightened as growth and inflation have broadly moved up for the first time in several years. Here at home, risks seem both moderate and balanced, including the downside risk of lower inflation and the upside risk of labor market overheating. The Committee has been patient in raising rates, and that patience has paid dividends…. If the economy performs about as expected, I would view it as appropriate to continue to gradually raise rates.” - June 2017 speech to the Economic Club of New York (Graphic: The inflation conundrum - reut.rs/2za4ltY) Other issues may confront Powell in his confirmation hearings and as chair, such as whether to keep the current system of paying banks interest on their reserves as the main method of setting short term interest rates, and whether to rely on monetary policy rules: On Reserve Interest:   “Simple to operate and has provided good control over the federal funds rate.” - June 2017 speech to the Economic Club of New York (Graphic: Bank reserves at the Fed - reut.rs/2z7Qdl8) On Policy Rules:  “I am unable to think of any critical, complex human activity that could be safely reduced to a simple summary equation. In particular, no major central bank uses policy rules in a prescriptive way, and it is hard to predict the consequences of requiring the FOMC to do so, as some have proposed. Policy should be systematic, but not automatic.” - February 2017 speech to the Forecasters Club of New York (Graphic: Monetary policy rules vs reality - reut.rs/2h7mMZE)\n","\n","this news is real\n"]}],"source":["#visualisation d'exemple\n","print(data['train']['complete_prompt'][2])"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T23:36:22.714279Z","iopub.status.busy":"2024-06-05T23:36:22.713367Z","iopub.status.idle":"2024-06-05T23:36:22.719229Z","shell.execute_reply":"2024-06-05T23:36:22.718323Z","shell.execute_reply.started":"2024-06-05T23:36:22.714247Z"},"trusted":true},"outputs":[],"source":["# Définition du jeton de padding comme le jeton de fin de séquence (EOS) du tokenizer.\n","tokenizer.pad_token = tokenizer.eos_token\n","# Ajout du jeton spécial [PAD] au tokenizer.\n","tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","\n","# Fonction pour tokeniser chaque exemple du dataset en ajoutant un padding pour atteindre une longueur maximale de 512 tokens.\n","def tokenize_dataset(example):\n","    response = tokenizer(example['complete_prompt'], padding='max_length', truncation=True, max_length=512)\n","    return response"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T23:36:26.776621Z","iopub.status.busy":"2024-06-05T23:36:26.775673Z","iopub.status.idle":"2024-06-05T23:37:16.846009Z","shell.execute_reply":"2024-06-05T23:37:16.844947Z","shell.execute_reply.started":"2024-06-05T23:36:26.776578Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a09f3a093a2949b3a3aedc7f5b296c41","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a295357de0434418a849dfe51b1ed1dd","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f17f9f13c3144eabb9f2603def52e7b7","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/8267 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Application de la fonction de tokenisation à l'ensemble du dataset (batched)\n","data = data.map(tokenize_dataset, batched=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T23:37:30.762544Z","iopub.status.busy":"2024-06-05T23:37:30.762196Z","iopub.status.idle":"2024-06-05T23:37:30.776685Z","shell.execute_reply":"2024-06-05T23:37:30.775868Z","shell.execute_reply.started":"2024-06-05T23:37:30.762518Z"},"trusted":true},"outputs":[],"source":["# Suppression des colonnes inutiles du dataset et mise en forme des données restantes pour l'utilisation avec PyTorch.\n","data = data.remove_columns(['title', 'subject', 'text', 'Unnamed: 0'])\n","data.set_format('torch', columns=['input_ids','prompt', 'attention_mask', 'label','complete_prompt'])"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T23:37:34.809117Z","iopub.status.busy":"2024-06-05T23:37:34.808755Z","iopub.status.idle":"2024-06-05T23:37:34.815299Z","shell.execute_reply":"2024-06-05T23:37:34.814343Z","shell.execute_reply.started":"2024-06-05T23:37:34.809091Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['date', 'label', 'prompt', 'complete_prompt', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 30000\n","    })\n","    validation: Dataset({\n","        features: ['date', 'label', 'prompt', 'complete_prompt', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 6000\n","    })\n","    test: Dataset({\n","        features: ['date', 'label', 'prompt', 'complete_prompt', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 8267\n","    })\n","})"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"markdown","metadata":{},"source":["# **Fine-tuning du Model**"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T23:37:40.192351Z","iopub.status.busy":"2024-06-05T23:37:40.191995Z","iopub.status.idle":"2024-06-05T23:37:40.198477Z","shell.execute_reply":"2024-06-05T23:37:40.197371Z","shell.execute_reply.started":"2024-06-05T23:37:40.192326Z"},"trusted":true},"outputs":[],"source":["def print_trainable_parameters(model):\n","     \"\"\"\n","    Affiche le nombre de paramètres entraînables dans le modèle.\n","    \"\"\"\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel() # Nombre total de paramètres\n","        if param.requires_grad:\n","            trainable_params += param.numel()  # Nombre de paramètres entraînables\n","    print(\n","        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n","    )"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T23:37:44.068827Z","iopub.status.busy":"2024-06-05T23:37:44.068433Z","iopub.status.idle":"2024-06-05T23:37:44.075379Z","shell.execute_reply":"2024-06-05T23:37:44.074305Z","shell.execute_reply.started":"2024-06-05T23:37:44.068796Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 184423682 || all params: 184423682 || trainable%: 100.0\n"]}],"source":["print_trainable_parameters(model)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T23:37:48.604841Z","iopub.status.busy":"2024-06-05T23:37:48.604126Z","iopub.status.idle":"2024-06-06T01:48:50.413287Z","shell.execute_reply":"2024-06-06T01:48:50.412072Z","shell.execute_reply.started":"2024-06-05T23:37:48.604806Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240605_233807-na8o5o61</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/abaali2002/huggingface/runs/na8o5o61' target=\"_blank\">comfy-lake-8</a></strong> to <a href='https://wandb.ai/abaali2002/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/abaali2002/huggingface' target=\"_blank\">https://wandb.ai/abaali2002/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/abaali2002/huggingface/runs/na8o5o61' target=\"_blank\">https://wandb.ai/abaali2002/huggingface/runs/na8o5o61</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5625' max='5625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5625/5625 2:10:21, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.000000</td>\n","      <td>0.000005</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.000000</td>\n","      <td>0.000001</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.000000</td>\n","      <td>0.000001</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/plain":["TrainOutput(global_step=5625, training_loss=0.003989431050067975, metrics={'train_runtime': 7859.8613, 'train_samples_per_second': 11.451, 'train_steps_per_second': 0.716, 'total_flos': 2.368041965568e+16, 'train_loss': 0.003989431050067975, 'epoch': 3.0})"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Arguments de l'entraînement\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",  # Répertoire de sortie pour les résultats\n","    evaluation_strategy=\"epoch\",  # Stratégie d'évaluation après chaque époque\n","    learning_rate=2e-5,   # Taux d'apprentissage\n","    per_device_train_batch_size=8,  # Taille du batch d'entraînement par appareil\n","    per_device_eval_batch_size=8,  # Taille du batch d'évaluation par appareil\n","    num_train_epochs=3,  # Nombre d'époques d'entraînement\n","    weight_decay=0.01,  # Décroissance de poids\n","    save_total_limit=1,  # Limite du nombre total de sauvegardes\n","    save_steps=1000,  # Sauvegarde tous les 1000 pas\n","    logging_dir='./logs',   # Répertoire de journalisation\n","    report_to=\"none\", #désactiver le W&B\n",")\n","\n","# Initialiser le Trainer\n","trainer = Trainer(\n","    model=model, \n","    args=training_args,\n","    train_dataset=data[\"train\"],\n","    eval_dataset=data[\"validation\"],\n","    tokenizer=tokenizer,\n",")\n","\n","# Affiner l'ensemble du modèle\n","trainer.train()"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-06T01:49:03.193980Z","iopub.status.busy":"2024-06-06T01:49:03.193223Z","iopub.status.idle":"2024-06-06T01:49:06.138492Z","shell.execute_reply":"2024-06-06T01:49:06.137421Z","shell.execute_reply.started":"2024-06-06T01:49:03.193950Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]}],"source":["# Sauvegardons le modèle entraîné dans le répertoire 'outputs'\n","trainer.model.save_pretrained('outputs')\n","# Rechargeons le tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\" )"]},{"cell_type":"markdown","metadata":{},"source":["# Test de la sortie du modèle affiné"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-06T01:49:11.872419Z","iopub.status.busy":"2024-06-06T01:49:11.871754Z","iopub.status.idle":"2024-06-06T01:49:13.105221Z","shell.execute_reply":"2024-06-06T01:49:13.104154Z","shell.execute_reply.started":"2024-06-06T01:49:11.872387Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted class: 0\n"]}],"source":["def classify_text(prompt):\n","    # Tokenizer l'entrée\n","    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(model.device)\n","\n","    # Obtenir les prédictions du modèle\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","    \n","    # Obtenir la classe prédite\n","    logits = outputs.logits\n","    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n","    predicted_class = torch.argmax(probabilities, dim=-1).item()\n","\n","    return predicted_class\n","\n","# Tester la fonction de classification\n","n = 100  # Index de l'exemple de test\n","prompt = data['test']['prompt'][n]\n","predicted_class = classify_text(prompt)\n","print(f\"Predicted class: {predicted_class}\")"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T23:26:44.458070Z","iopub.status.busy":"2024-06-05T23:26:44.457702Z","iopub.status.idle":"2024-06-05T23:26:44.474349Z","shell.execute_reply":"2024-06-05T23:26:44.473541Z","shell.execute_reply.started":"2024-06-05T23:26:44.458044Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor(0)"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["#Vérification\n","data['test']['label'][100]"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-06-06T02:36:51.046937Z","iopub.status.busy":"2024-06-06T02:36:51.046433Z","iopub.status.idle":"2024-06-06T02:38:33.623113Z","shell.execute_reply":"2024-06-06T02:38:33.622165Z","shell.execute_reply.started":"2024-06-06T02:36:51.046877Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","10\n","20\n","30\n","40\n","50\n","60\n","70\n","80\n","90\n","1.0\n"]}],"source":["#évaluer la performance du modèle\n","correct=0\n","for i in range(100):\n","  prompt = data['validation']['prompt'][i]\n","  if classify_text(prompt) == data['validation']['label'][i]:\n","    correct+=1\n","  if i%10==0:\n","    print(i)\n","# Afficher le pourcentage de précision\n","print(correct/100)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-06-06T01:49:46.087205Z","iopub.status.busy":"2024-06-06T01:49:46.086811Z","iopub.status.idle":"2024-06-06T01:49:46.125461Z","shell.execute_reply":"2024-06-06T01:49:46.124374Z","shell.execute_reply.started":"2024-06-06T01:49:46.087174Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted class: 0\n"]}],"source":["#teste de la fonction classify_text sur un prompt quelconque\n","prompt = 'usa is not a country'\n","predicted_class = classify_text(prompt)\n","print(f\"Predicted class: {predicted_class}\")"]},{"cell_type":"markdown","metadata":{},"source":["# UI: Streamlit"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-06-06T02:04:07.051293Z","iopub.status.busy":"2024-06-06T02:04:07.050501Z","iopub.status.idle":"2024-06-06T02:04:07.059650Z","shell.execute_reply":"2024-06-06T02:04:07.058599Z","shell.execute_reply.started":"2024-06-06T02:04:07.051246Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting app.py\n"]}],"source":["%%writefile app.py\n","import streamlit as st\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","# Definir le model afiné\n","model = AutoModelForSequenceClassification.from_pretrained(\"outputs\")\n","# Definir le tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n","\n","#  interface Streamlit app\n","st.title(\"Fake News Detection with DeBERTa\")\n","\n","uploaded_text = st.text_area(\"Enter news text here...\")\n","\n","if st.button(\"Classify\"):\n","    if uploaded_text:\n","        inputs = tokenizer(uploaded_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(model.device)\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","        logits = outputs.logits\n","        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n","        predicted_class = torch.argmax(probabilities, dim=-1).item()\n","        class_name = \"Fake\" if predicted_class == 0 else \"Real\"\n","        st.write(f\"Predicted class: {class_name}\")\n","    else:\n","        st.write(\"Please enter some text to classify.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"trusted":true},"outputs":[],"source":["#installation de Node.js, npm et Streamlit, ainsi que le package localtunnel via npm\n","!apt-get install -y nodejs npm\n","!npm install -g localtunnel\n","!pip install streamlit"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-06-06T02:04:10.174240Z","iopub.status.busy":"2024-06-06T02:04:10.173851Z","iopub.status.idle":"2024-06-06T02:14:52.338955Z","shell.execute_reply":"2024-06-06T02:14:52.337713Z","shell.execute_reply.started":"2024-06-06T02:04:10.174213Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n","\u001b[0m\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.19.2.2:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.226.65.76:8501\u001b[0m\n","\u001b[0m\n","your url is: https://old-bottles-accept.loca.lt\n","/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","^C\n","\u001b[34m  Stopping...\u001b[0m\n"]}],"source":["#On exécute l'application Streamlit localement via localtunnel sur le port 8501.\n","!streamlit run app.py & npx localtunnel --port 8501"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30700,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
